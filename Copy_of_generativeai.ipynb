{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sara23523/SWE485-Group16-recommendation-system-/blob/main/Copy_of_generativeai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 4: Integrating Generative AI into the Restaurant Recommendation System"
      ],
      "metadata": {
        "id": "1IqZexrQHhbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "# Load the notebook\n",
        "with open(\"GenerativeAI.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Check metadata\n",
        "print(nb.metadata.get(\"widgets\", \"‚úÖ No widgets metadata found!\"))\n"
      ],
      "metadata": {
        "id": "YNvsU-ohdx6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase Overview**\n"
      ],
      "metadata": {
        "id": "5TpSnLgiHCFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this phase, we integrated a Generative AI model ‚Äî FLAN-T5‚Äî\n",
        "into the system to enhance user interaction through intelligent, human like explanations and recommendations.\n",
        "\n",
        "Instead of only presenting filtered restaurant results, the system now uses these models to generate natural language responses based on the user‚Äôs input and selected restaurant data.\n",
        "\n",
        "This allows the system to provide context-aware suggestions, explain why a certain restaurant matches the user's preferences, and offer more engaging, informative, and personalized feedback.\n",
        "\n",
        "The integration involved designing prompt templates, processing structured data into AI-readable inputs, and generating outputs that improve the overall user experience."
      ],
      "metadata": {
        "id": "5weDo33WIzLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Dataset Preparation and Exploration**\n"
      ],
      "metadata": {
        "id": "7Da-QVAbHv0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"https://raw.githubusercontent.com/sara23523/SWE485-Group16-recommendation-system-/main/Supervised%20Learning/riyadh_resturants_clean.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preview the data\n",
        "print(\"üîπ First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check basic info\n",
        "print(\"\\nüîπ Dataset Info:\")\n",
        "df.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nüîπ Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Summary statistics for numerical columns\n",
        "print(\"\\nüîπ Descriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for unique values in each column (for categoricals)\n",
        "print(\"\\nüîπ Unique values per column:\")\n",
        "for col in df.columns:\n",
        "    unique_vals = df[col].nunique()\n",
        "    print(f\"{col}: {unique_vals} unique values\")\n",
        "\n",
        "# Visualize distributions of numerical features\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "df[numeric_cols].hist(bins=15, figsize=(15, 10))\n",
        "plt.suptitle(\"Distributions of Numerical Features\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap (for numerical features)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "#  Convert categorical variables to lowercase strings for consistency\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda x: x.str.strip().str.lower())\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1. Drop rows where rating is missing\n",
        "df_clean = df.dropna(subset=['rating'])\n",
        "\n",
        "# OR Keep them but treat missing ratings differently\n",
        "def clean_data(df):\n",
        "    df['rating'].fillna(-1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 2. Fill missing values in other fields\n",
        "df_clean = df.dropna(subset=['rating']).copy()\n",
        "\n",
        "df_clean.loc[:, 'ratingSignals'] = df_clean['ratingSignals'].fillna(0)\n",
        "df_clean.loc[:, 'likes'] = df_clean['likes'].fillna(0)\n",
        "\n",
        "df_clean['price'] = df_clean['price'].fillna(\"Unknown\")\n",
        "\n",
        "# 3. Log transform skewed numerical features\n",
        "for col in ['likes', 'photos', 'tips', 'ratingSignals']:\n",
        "    df_clean[f'{col}_log'] = np.log1p(df_clean[col])  # log(1 + x) to avoid log(0)\n",
        "\n",
        "# 4. Normalize/encode categorical values (if needed later)\n",
        "df_clean['price_encoded'] = df_clean['price'].map({\n",
        "    'cheap': 1,\n",
        "    'moderate': 2,\n",
        "    'expensive': 3,\n",
        "    'very expensive': 4,\n",
        "    'unknown': 0\n",
        "})\n",
        "\n",
        "#  Extract top categories\n",
        "top_cats = df_clean['categories'].value_counts().nlargest(20).index\n",
        "df_clean['category_clean'] = df_clean['categories'].apply(\n",
        "    lambda x: x if x in top_cats else 'Other'\n",
        ")\n",
        "\n",
        "# 5. Preview cleaned dataset\n",
        "print()\n",
        "print()\n",
        "print(df_clean.head(5))\n"
      ],
      "metadata": {
        "id": "br5ls9j9Izu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rationale Behind Data Preprocessing**"
      ],
      "metadata": {
        "id": "gPmiuLv-Sk_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ **Data Visualization**\n",
        "\n",
        "The heatmap explores correlations between numerical features, essential for detecting multicollinearity. Highly correlated features may need to be combined or excluded to prevent redundancy and improve model performance.\n",
        "\n",
        "üîπ **Text Normalization**\n",
        "\n",
        "String values are converted to lowercase and extra spaces removed, ensuring consistent data for better matching and grouping in further analysis.\n",
        "\n",
        "üîπ **Handling Missing Data**\n",
        "\n",
        "Dropped rows with missing rating and filled missing ratingSignals, likes, and price to ensure data completeness and integrity for analysis.\n",
        "\n",
        "üîπ **Feature Transformation (Skew Handling)**\n",
        "\n",
        "Applied log1p to right-skewed features to reduce skewness, stabilize variance, and improve model performance.\n",
        "\n",
        "üîπ **Encoding and Category Simplification**\n",
        "\n",
        "Encoded price numerically and grouped rare categories as \"Other\" to prepare data for ML models and reduce sparsity for better generalization."
      ],
      "metadata": {
        "id": "bPWi_KuKXtWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Integration of Generative AI & Application of Two Different AI Templates**"
      ],
      "metadata": {
        "id": "l3RHckrQH97e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using FLAN-T5\n",
        "\n",
        "# Install Required Libraries\n",
        "!pip install -q transformers accelerate huggingface_hub\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Load Dataset\n",
        "dataset_path = \"https://raw.githubusercontent.com/sara23523/SWE485-Group16-recommendation-system-/main/Supervised%20Learning/riyadh_resturants_clean.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocess Dataset\n",
        "df = df.dropna(subset=['rating'])  # drop rows with missing ratings\n",
        "\n",
        "# Fill missing 'price' with most frequent value\n",
        "df['price'] = df['price'].fillna(df['price'].mode()[0])\n",
        "\n",
        "# Optional: Categorize price into descriptive labels\n",
        "price_mapping = {'$': 'Cheap', '$$': 'Moderate', '$$$': 'Expensive', '$$$$': 'Very Expensive'}\n",
        "df['price'] = df['price'].map(price_mapping).fillna('Unknown')\n",
        "\n",
        "# Display sample of cleaned data\n",
        "df_cleaned = df[['name', 'categories', 'price', 'rating']].head(10)\n",
        "df_cleaned\n",
        "\n",
        "# Load FLAN-T5 Model Pipeline\n",
        "flan = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "0\n",
        "\n",
        "# Define Prompt Templates\n",
        "\n",
        "prompt_1 = f\"\"\"\n",
        "You are a restaurant assistant. Recommend 3 restaurants from this list with a high rating and moderate price.\n",
        "\n",
        "List:\n",
        "1. {df_cleaned.iloc[0]['name']} - {df_cleaned.iloc[0]['categories']}, Price: {df_cleaned.iloc[0]['price']}, Rating: {df_cleaned.iloc[0]['rating']}\n",
        "2. {df_cleaned.iloc[1]['name']} - {df_cleaned.iloc[1]['categories']}, Price: {df_cleaned.iloc[1]['price']}, Rating: {df_cleaned.iloc[1]['rating']}\n",
        "3. {df_cleaned.iloc[2]['name']} - {df_cleaned.iloc[2]['categories']}, Price: {df_cleaned.iloc[2]['price']}, Rating: {df_cleaned.iloc[2]['rating']}\n",
        "4. {df_cleaned.iloc[3]['name']} - {df_cleaned.iloc[3]['categories']}, Price: {df_cleaned.iloc[3]['price']}, Rating: {df_cleaned.iloc[3]['rating']}\n",
        "5. {df_cleaned.iloc[4]['name']} - {df_cleaned.iloc[4]['categories']}, Price: {df_cleaned.iloc[4]['price']}, Rating: {df_cleaned.iloc[4]['rating']}\n",
        "\n",
        "Please suggest the top 3 and explain briefly why.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 2: Ask for 3 cheap/popular places\n",
        "prompt_2 = f\"\"\"\n",
        "You are helping a tourist looking for 3 cheap and popular food places in Riyadh.\n",
        "\n",
        "Choices:\n",
        "1. {df_cleaned.iloc[5]['name']} - {df_cleaned.iloc[5]['categories']}, Price: {df_cleaned.iloc[5]['price']}, Rating: {df_cleaned.iloc[5]['rating']}\n",
        "2. {df_cleaned.iloc[6]['name']} - {df_cleaned.iloc[6]['categories']}, Price: {df_cleaned.iloc[6]['price']}, Rating: {df_cleaned.iloc[6]['rating']}\n",
        "3. {df_cleaned.iloc[7]['name']} - {df_cleaned.iloc[7]['categories']}, Price: {df_cleaned.iloc[7]['price']}, Rating: {df_cleaned.iloc[7]['rating']}\n",
        "4. {df_cleaned.iloc[8]['name']} - {df_cleaned.iloc[8]['categories']}, Price: {df_cleaned.iloc[8]['price']}, Rating: {df_cleaned.iloc[8]['rating']}\n",
        "5. {df_cleaned.iloc[9]['name']} - {df_cleaned.iloc[9]['categories']}, Price: {df_cleaned.iloc[9]['price']}, Rating: {df_cleaned.iloc[9]['rating']}\n",
        "\n",
        "Suggest 3 restaurants and explain why each is suitable for a tourist.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 3: Ask for 3 restaurants for a family day out in Riyadh.\n",
        "prompt_3 = f\"\"\"\n",
        "You are a helpful assistant recommending restaurants for a family day out in Riyadh.\n",
        "The user is looking for family-friendly places that are budget-friendly and have decent ratings.\n",
        "Here are some options:\n",
        "\n",
        "{df_cleaned.iloc[7]['name']} - {df_cleaned.iloc[7]['categories']}, Rating: {df_cleaned.iloc[7]['rating']}, Price: {df_cleaned.iloc[7]['price']}\n",
        "{df_cleaned.iloc[8]['name']} - {df_cleaned.iloc[8]['categories']}, Rating: {df_cleaned.iloc[8]['rating']}, Price: {df_cleaned.iloc[8]['price']}\n",
        "{df_cleaned.iloc[9]['name']} - {df_cleaned.iloc[9]['categories']}, Rating: {df_cleaned.iloc[9]['rating']}, Price: {df_cleaned.iloc[9]['price']}\n",
        "{df_cleaned.iloc[0]['name']} - {df_cleaned.iloc[0]['categories']}, Rating: {df_cleaned.iloc[0]['rating']}, Price: {df_cleaned.iloc[0]['price']}\n",
        "{df_cleaned.iloc[1]['name']} - {df_cleaned.iloc[1]['categories']}, Rating: {df_cleaned.iloc[1]['rating']}, Price: {df_cleaned.iloc[1]['price']}\n",
        "\n",
        "Suggest 3 restaurants and explain briefly why they are great for families.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 1 Response\n",
        "print(\"üîπ Prompt 1 Response (Top 3 High Rating + Moderate Price):\")\n",
        "response_1 = flan(prompt_1, max_new_tokens=200)[0]['generated_text']\n",
        "print(response_1)\n",
        "\n",
        "# Prompt 2 Response\n",
        "print(\"\\nüîπ Prompt 2 Response (Top 3 Cheap + Popular for Tourist):\")\n",
        "response_2 = flan(prompt_2, max_new_tokens=200)[0]['generated_text']\n",
        "print(response_2)\n",
        "\n",
        "# Prompt 3 Response\n",
        "print(\"üîπ Prompt 3 Responses (Family + Budget):\\n\")\n",
        "response_3 = flan(prompt_3, max_new_tokens=200)[0]['generated_text']\n",
        "print(response_3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wkxCHWfFQGE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Simulating User Interactions for Restaurant Recommendations**"
      ],
      "metadata": {
        "id": "H2JJhzzQIW2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers accelerate huggingface_hub\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load dataset\n",
        "dataset_url = \"https://raw.githubusercontent.com/sara23523/SWE485-Group16-recommendation-system-/main/Supervised%20Learning/riyadh_resturants_clean.csv\"\n",
        "df = pd.read_csv(dataset_url)\n",
        "\n",
        "# Preprocess\n",
        "df = df.dropna(subset=['rating'])\n",
        "df['price'] = df['price'].fillna(df['price'].mode()[0])\n",
        "price_map = {'$': 'Cheap', '$$': 'Moderate', '$$$': 'Expensive', '$$$$': 'Very Expensive'}\n",
        "df['price'] = df['price'].map(price_map).fillna('Unknown')\n",
        "\n",
        "# Load FLAN-T5\n",
        "flan = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n"
      ],
      "metadata": {
        "id": "OC6xuYaNaO48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define Prompt Builder from User Input"
      ],
      "metadata": {
        "id": "yYMVYQ63yqEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt_from_query(user_query, filtered_df):\n",
        "    restaurant_list = []\n",
        "    for idx, row in filtered_df.iterrows():\n",
        "        restaurant_list.append(f\"{row['name']} - {row['categories']}, Price: {row['price']}, Rating: {row['rating']}\")\n",
        "    restaurant_str = \"\\n\".join(restaurant_list[:5])  # Use top 5 for brevity\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful AI assistant recommending restaurants in Riyadh.\n",
        "\n",
        "User query: \"{user_query}\"\n",
        "\n",
        "Here are some restaurant options:\n",
        "{restaurant_str}\n",
        "\n",
        "Based on the user‚Äôs input, suggest 3 restaurants and explain briefly why each is a good choice.\n",
        "\"\"\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "UU4PHHKdynfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Simulate User Interaction Loop"
      ],
      "metadata": {
        "id": "Zk3O_QjGzD9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_user_interaction():\n",
        "    user_query = input(\"üßë‚Äçüí¨ What are you looking for? (e.g., 'cheap places with good reviews for families'): \").strip().lower()\n",
        "\n",
        "    # Basic keyword filtering\n",
        "    if \"cheap\" in user_query:\n",
        "        filtered_df = df[df['price'] == 'Cheap']\n",
        "    elif \"moderate\" in user_query:\n",
        "        filtered_df = df[df['price'] == 'Moderate']\n",
        "    elif \"expensive\" in user_query:\n",
        "        filtered_df = df[df['price'].isin(['Expensive', 'Very Expensive'])]\n",
        "    else:\n",
        "        filtered_df = df.copy()\n",
        "\n",
        "    if \"high rating\" in user_query or \"good reviews\" in user_query:\n",
        "        filtered_df = filtered_df[filtered_df['rating'] >= 4.0]\n",
        "    elif \"decent\" in user_query or \"okay\" in user_query:\n",
        "        filtered_df = filtered_df[filtered_df['rating'] >= 3.5]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        print(\"‚ùå No restaurants match the current search criteria.\")\n",
        "        return\n",
        "\n",
        "    # Sort and get top N for prompt\n",
        "    filtered_df = filtered_df.sort_values(by=\"rating\", ascending=False).head(5)\n",
        "    prompt = build_prompt_from_query(user_query, filtered_df)\n",
        "\n",
        "    print(\"\\nüì® Generated Prompt:\\n\", prompt)\n",
        "\n",
        "    print(\"\\nü§ñ FLAN-T5 Response:\\n\")\n",
        "    response = flan(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "    print(response)\n"
      ],
      "metadata": {
        "id": "OvMTGHrVyt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_user_interaction()\n"
      ],
      "metadata": {
        "id": "iRaOIH8DzFZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_user_interaction()"
      ],
      "metadata": {
        "id": "1EXcS7LQbzqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_user_interaction()"
      ],
      "metadata": {
        "id": "4F0nRW9OcJCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Template Differences and Selection Justification**"
      ],
      "metadata": {
        "id": "5-VasQbsIhJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this phase, three distinct prompt templates were designed and applied to the FLAN-T5 model to recommend restaurants in Riyadh based on different user preferences and contextual requirements. Each template followed a specific scenario and instruction set to test the model‚Äôs flexibility in generating appropriate recommendations.\n",
        "\n",
        "### Prompt Template Overview:\n",
        "\n",
        "| Template | Scenario | User Preference | Structure | Selection Criteria |\n",
        "|:------------|:------------|:-----------------|:----------------|:------------------|\n",
        "| **Prompt 1** | Recommend top 3 restaurants | High rating and moderate price | Direct list of options with ratings and prices, asking for recommendations and brief reasoning | Assess model‚Äôs ability to prioritize based on rating and price |\n",
        "| **Prompt 2** | Suggest 3 cheap and popular places for tourists | Cheap price and popularity | Direct list with explicit cheap price filtering | Test model‚Äôs sensitivity to budget-friendly filtering |\n",
        "| **Prompt 3** | Recommend family-friendly restaurants | Budget-friendly and decent rating for families | Casual instruction with list of options and emphasis on family suitability | Evaluate model‚Äôs ability to address context-specific needs |\n",
        "\n",
        "---\n",
        "\n",
        "### Differences in Template Logic:\n",
        "- **Prompt 1** focuses on sorting based on numeric rating and a specific price tier.\n",
        "- **Prompt 2** shifts the focus towards affordability and implied popularity.\n",
        "- **Prompt 3** introduces contextual suitability (family-friendly) in addition to price and rating.\n",
        "\n",
        "---\n",
        "\n",
        "### Selection Justification:\n",
        "Using multiple prompt templates allowed for a comprehensive evaluation of the model's capacity to adapt to various user needs and contextual cues. The diversity in prompt structures highlights how phrasing and emphasis affect the AI-generated responses.  \n",
        "\n",
        "Among these, **Prompt 1** and **Prompt 3** demonstrated superior balance between precision and relevance:\n",
        "- **Prompt 1** reliably filtered based on quantitative values (ratings and prices).\n",
        "- **Prompt 3** effectively handled context-sensitive advice (family outings), making it valuable for real-world assistant scenarios.\n",
        "\n",
        "As a result, these templates were identified as most aligned with the project‚Äôs objective of delivering tailored, explainable recommendations through Generative AI integration.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4N70_IFrSvQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "a-FS6sP_It_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The integration of FLAN-T5 with custom prompt templates successfully demonstrated the potential of Generative AI in providing dynamic, personalized restaurant recommendations based on varied user preferences. The experiment confirmed that template design significantly influences the quality and relevance of AI-generated content.\n",
        "\n",
        "By experimenting with multiple prompt structures, it was evident that:\n",
        "- **Template 1** excelled in structured, value-based recommendations.\n",
        "- **Template 3** provided effective context-driven advice suitable for specialized user needs.\n",
        "\n",
        "This phase emphasized the importance of prompt engineering in Generative AI applications, particularly for recommendation systems where user preferences and context critically affect output quality.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yPyfEAwPI3mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "notebook_path = \"C:\\\\Users\\\\96650\\\\Downloads\\\\GenerativeAI.ipynb\" #Corrected path\n",
        "\n",
        "import nbformat\n",
        "\n",
        "# Load the notebook file\n",
        "notebook_path = \"GenerativeAI.ipynb\"  # Change this to your actual notebook name\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    notebook = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Clean metadata.widgets\n",
        "if 'widgets' in notebook['metadata']:\n",
        "    if 'state' not in notebook['metadata']['widgets']:\n",
        "        print(\"‚ö†Ô∏è 'state' key missing in metadata.widgets. Removing 'widgets' metadata.\")\n",
        "        del notebook['metadata']['widgets']\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    nbformat.write(notebook, f)\n",
        "\n",
        "print(\"‚úÖ Notebook metadata cleaned.\")\n",
        "\n",
        "# Load the notebook file\n",
        "notebook_path = \"GenerativeAI.ipynb\"  # Change this to your actual notebook name\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    notebook = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Clean metadata.widgets\n",
        "if 'widgets' in notebook['metadata']:\n",
        "    if 'state' not in notebook['metadata']['widgets']:\n",
        "        print(\"‚ö†Ô∏è 'state' key missing in metadata.widgets. Removing 'widgets' metadata.\")\n",
        "        del notebook['metadata']['widgets']\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    nbformat.write(notebook, f)\n",
        "\n",
        "print(\"‚úÖ Notebook metadata cleaned.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "elI_OAuAbL3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "# Load the notebook\n",
        "with open(\"GenerativeAI.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Check metadata\n",
        "print(nb.metadata.get(\"widgets\", \"‚úÖ No widgets metadata found!\"))\n"
      ],
      "metadata": {
        "id": "53zD6CgQcJ5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "file = \"GenerativeAI.ipynb\"\n",
        "\n",
        "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Remove 'widgets' metadata if exists\n",
        "if \"widgets\" in nb.metadata:\n",
        "    del nb.metadata[\"widgets\"]\n",
        "\n",
        "# Also remove from each cell\n",
        "for cell in nb.cells:\n",
        "    if \"widgets\" in cell.get(\"metadata\", {}):\n",
        "        del cell[\"metadata\"][\"widgets\"]\n",
        "\n",
        "with open(file, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\"‚úÖ Cleaned notebook metadata completely.\")\n"
      ],
      "metadata": {
        "id": "7i9EBw_kc6X0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}